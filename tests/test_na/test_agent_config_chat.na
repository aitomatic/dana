# Test agent chat with config-based LLM parameters

# Define an agent blueprint with LLM config
agent_blueprint SmartAgent:
    name: str = "Smart Agent"
    config: dict = {
        "llm_model": "openai:gpt-4o-mini",
        "llm_temperature": 0.3
    }

# Create instance from blueprint
smart_agent = SmartAgent()

print("=== Agent Config Chat Test ===")
print("SmartAgent type:", type(smart_agent))
print("SmartAgent config:", smart_agent.config)

# Test chat functionality
print("\n--- Testing Chat ---")
response = smart_agent.chat("Hello! What model are you using?")
print("Response:", response)
print("Response type:", type(response))
