# Test agent LLM parameters functionality

# Define an agent blueprint with LLM parameters
agent_blueprint SmartAgent:
    name: str = "Smart Agent"
    expertise: str = "general"
    llm_params:
        model = "openai:gpt-4o-mini"
        temperature = 0.3
        max_tokens = 1000

# Create instance from blueprint
smart_agent = SmartAgent()

# Create singleton agent with custom LLM parameters
agent CustomAgent(SmartAgent):
    expertise = "coding"
    llm_params:
        model = "anthropic:claude-3-sonnet"
        temperature = 0.1

# Create simple agent with LLM parameters
agent SimpleAgent:
    llm_params:
        model = "openai:gpt-3.5-turbo"
        temperature = 0.7

print("=== Agent LLM Parameters Test ===")
print("SmartAgent type:", type(smart_agent))
print("CustomAgent type:", type(CustomAgent))
print("SimpleAgent type:", type(SimpleAgent))

# Test chat functionality
print("\n--- Testing SmartAgent ---")
response1 = smart_agent.chat("Hello! What model are you using?")
print("Response:", response1)

print("\n--- Testing CustomAgent ---")
response2 = CustomAgent.chat("Hello! What model are you using?")
print("Response:", response2)

print("\n--- Testing SimpleAgent ---")
response3 = SimpleAgent.chat("Hello! What model are you using?")
print("Response:", response3)
