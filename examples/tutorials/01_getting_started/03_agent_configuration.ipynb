{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Configuration in OpenDXA\n",
    "\n",
    "This tutorial covers how to configure OpenDXA agents with different settings, resources, and behaviors. We'll explore various configuration options and how they affect agent performance.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Understanding of OpenDXA basics (from [Introduction to OpenDXA](01_introduction_to_dxa.ipynb))\n",
    "- Familiarity with simple workflows (from [Simple Workflows](02_simple_workflows.ipynb))\n",
    "- OpenDXA package installed\n",
    "- Python 3.8 or higher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Agent Configuration\n",
    "\n",
    "Let's start with the basic configuration options available when creating an agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opendxa import Agent\n",
    "from opendxa.execution import ExecutionContext\n",
    "\n",
    "# Create an agent with basic configuration\n",
    "agent = Agent(\n",
    "    name=\"configured_agent\",\n",
    "    description=\"An agent with custom configuration\",\n",
    "    execution_context=ExecutionContext()\n",
    ")\n",
    "\n",
    "# Print agent configuration\n",
    "print(f\"Agent Name: {agent.name}\")\n",
    "print(f\"Agent Description: {agent.description}\")\n",
    "print(f\"Execution Context: {agent.execution_context}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LLM Resource Configuration\n",
    "\n",
    "One of the most important aspects of agent configuration is setting up the LLM (Language Model) resources. Let's see how to configure different LLM providers and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opendxa.common.resource import LLMResource\n",
    "from opendxa.common.resource.llm.providers import OpenAIProvider, AnthropicProvider\n",
    "\n",
    "# Configure OpenAI provider\n",
    "openai_provider = OpenAIProvider(\n",
    "    model=\"gpt-4\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=1000\n",
    ")\n",
    "\n",
    "# Configure Anthropic provider\n",
    "anthropic_provider = AnthropicProvider(\n",
    "    model=\"claude-3-opus-20240229\",\n",
    "    temperature=0.5,\n",
    "    max_tokens=2000\n",
    ")\n",
    "\n",
    "# Create LLM resources\n",
    "openai_resource = LLMResource(provider=openai_provider)\n",
    "anthropic_resource = LLMResource(provider=anthropic_provider)\n",
    "\n",
    "# Create an agent with specific LLM resource\n",
    "agent = Agent(\n",
    "    name=\"llm_configured_agent\",\n",
    "    llm_resource=openai_resource  # or anthropic_resource\n",
    ")\n",
    "\n",
    "# Test the agent with the configured LLM\n",
    "response = agent.ask(\"What are the key features of OpenDXA?\")\n",
    "print(response['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Workflow Configuration\n",
    "\n",
    "We can configure how the agent handles workflows, including custom workflow types and execution strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opendxa.execution.workflow import Workflow\n",
    "from opendxa.execution.workflow.workflow_factory import WorkflowFactory\n",
    "\n",
    "# Create a custom workflow\n",
    "custom_workflow = Workflow(\n",
    "    name=\"custom_workflow\",\n",
    "    description=\"A workflow with custom configuration\"\n",
    ")\n",
    "\n",
    "# Configure workflow factory\n",
    "workflow_factory = WorkflowFactory(\n",
    "    default_workflow=custom_workflow,\n",
    "    workflow_types={\"custom\": custom_workflow}\n",
    ")\n",
    "\n",
    "# Create an agent with custom workflow configuration\n",
    "agent = Agent(\n",
    "    name=\"workflow_configured_agent\",\n",
    "    workflow_factory=workflow_factory\n",
    ")\n",
    "\n",
    "# Test the agent with custom workflow\n",
    "response = agent.ask(\"Analyze this manufacturing data\", workflow_type=\"custom\")\n",
    "print(response['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Planning Configuration\n",
    "\n",
    "Let's see how to configure the planning layer of the agent, which determines how tasks are broken down and executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opendxa.execution.planning import PlanFactory\n",
    "from opendxa.execution.planning.strategies import LinearPlanningStrategy, ParallelPlanningStrategy\n",
    "\n",
    "# Configure planning strategies\n",
    "linear_strategy = LinearPlanningStrategy()\n",
    "parallel_strategy = ParallelPlanningStrategy()\n",
    "\n",
    "# Create plan factory with custom strategies\n",
    "plan_factory = PlanFactory(\n",
    "    default_strategy=linear_strategy,\n",
    "    strategies={\n",
    "        \"linear\": linear_strategy,\n",
    "        \"parallel\": parallel_strategy\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create an agent with custom planning configuration\n",
    "agent = Agent(\n",
    "    name=\"planning_configured_agent\",\n",
    "    plan_factory=plan_factory\n",
    ")\n",
    "\n",
    "# Test the agent with different planning strategies\n",
    "response = agent.ask(\"Process this batch of data\", planning_strategy=\"parallel\")\n",
    "print(response['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Reasoning Configuration\n",
    "\n",
    "Finally, let's configure the reasoning layer, which handles the actual execution of tasks and decision-making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opendxa.execution.reasoning import ReasoningFactory\n",
    "from opendxa.execution.reasoning.strategies import ChainOfThoughtStrategy, OODAStrategy\n",
    "\n",
    "# Configure reasoning strategies\n",
    "cot_strategy = ChainOfThoughtStrategy()\n",
    "ooda_strategy = OODAStrategy()\n",
    "\n",
    "# Create reasoning factory with custom strategies\n",
    "reasoning_factory = ReasoningFactory(\n",
    "    default_strategy=cot_strategy,\n",
    "    strategies={\n",
    "        \"chain_of_thought\": cot_strategy,\n",
    "        \"ooda\": ooda_strategy\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create an agent with custom reasoning configuration\n",
    "agent = Agent(\n",
    "    name=\"reasoning_configured_agent\",\n",
    "    reasoning_factory=reasoning_factory\n",
    ")\n",
    "\n",
    "# Test the agent with different reasoning strategies\n",
    "response = agent.ask(\"Analyze this manufacturing process\", reasoning_strategy=\"ooda\")\n",
    "print(response['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Putting It All Together\n",
    "\n",
    "Let's create a fully configured agent with all the custom settings we've discussed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fully configured agent\n",
    "agent = Agent(\n",
    "    name=\"fully_configured_agent\",\n",
    "    description=\"An agent with comprehensive configuration\",\n",
    "    llm_resource=openai_resource,\n",
    "    workflow_factory=workflow_factory,\n",
    "    plan_factory=plan_factory,\n",
    "    reasoning_factory=reasoning_factory,\n",
    "    execution_context=ExecutionContext()\n",
    ")\n",
    "\n",
    "# Test the fully configured agent\n",
    "response = agent.ask(\n",
    "    \"Analyze this semiconductor manufacturing data\",\n",
    "    workflow_type=\"custom\",\n",
    "    planning_strategy=\"parallel\",\n",
    "    reasoning_strategy=\"ooda\"\n",
    ")\n",
    "print(response['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "In this tutorial, we've covered:\n",
    "\n",
    "1. Basic agent configuration\n",
    "2. LLM resource configuration\n",
    "3. Workflow configuration\n",
    "4. Planning configuration\n",
    "5. Reasoning configuration\n",
    "6. Creating a fully configured agent\n",
    "\n",
    "Now that you understand how to configure agents, you can move on to the Core Concepts tutorials to learn more about each layer of the OpenDXA architecture in detail."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
