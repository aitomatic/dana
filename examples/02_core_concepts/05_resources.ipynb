{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Resources in OpenDXA\n\nThis tutorial covers the resource system in OpenDXA, which provides a flexible way to manage and coordinate different types of resources used by agents in the planning and reasoning layers.\n\n## Learning Objectives\n\nBy the end of this tutorial, you will understand:\n\n1. Different types of resources in OpenDXA\n2. How to configure and manage resources\n3. Resource lifecycle management\n4. Resource pooling and optimization\n5. Best practices for resource usage\n\n## Prerequisites\n\n- Basic understanding of OpenDXA's 2-layer architecture (planning and reasoning)\n- Familiarity with Python async/await syntax\n- Understanding of basic resource management concepts\n\n## 1. Understanding Resource Types\n\nOpenDXA supports several types of resources that are used by both the planning and reasoning layers:\n\n1. **LLM Resources**: Language models for reasoning and generation\n2. **External API Resources**: Integration with external services\n3. **Database Resources**: Data storage and retrieval\n4. **Custom Resources**: User-defined resource types\n\nLet's explore each type:"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "from opendxa.common.resource import BaseResource\nfrom opendxa.common.resource import LLMResource\nfrom typing import Dict, Any, Optional\n\n# Example of a custom resource\nclass DatabaseResource(BaseResource):\n    \"\"\"Example database resource.\"\"\"\n    def __init__(self, connection_string: str):\n        super().__init__()\n        self.connection_string = connection_string\n        self._initialized = False\n        \n    async def initialize(self) -> None:\n        \"\"\"Initialize database connection.\"\"\"\n        print(f\"Connecting to database: {self.connection_string}\")\n        self._initialized = True\n        \n    async def cleanup(self) -> None:\n        \"\"\"Cleanup database connection.\"\"\"\n        print(\"Closing database connection\")\n        self._initialized = False\n        \n    async def query(self, query: str) -> Dict[str, Any]:\n        \"\"\"Execute a database query.\"\"\"\n        if not self._initialized:\n            raise RuntimeError(\"Resource not initialized\")\n        print(f\"Executing query: {query}\")\n        return {\"result\": \"query executed\"}\n\n# Example of an API resource\nclass APIResource(BaseResource):\n    \"\"\"Example API resource.\"\"\"\n    def __init__(self, base_url: str, api_key: Optional[str] = None):\n        super().__init__()\n        self.base_url = base_url\n        self.api_key = api_key\n        self._initialized = False\n        \n    async def initialize(self) -> None:\n        \"\"\"Initialize API connection.\"\"\"\n        print(f\"Initializing API connection to {self.base_url}\")\n        self._initialized = True\n        \n    async def cleanup(self) -> None:\n        \"\"\"Cleanup API connection.\"\"\"\n        print(\"Cleaning up API connection\")\n        self._initialized = False\n        \n    async def make_request(self, endpoint: str, method: str = \"GET\", data: Optional[Dict] = None) -> Dict[str, Any]:\n        \"\"\"Make an API request.\"\"\"\n        if not self._initialized:\n            raise RuntimeError(\"Resource not initialized\")\n        print(f\"Making {method} request to {endpoint}\")\n        return {\"status\": \"success\", \"data\": data or {}}"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Resource Configuration\n\nResources can be configured for use in both the planning and reasoning layers. Let's see how to set up different types of resources:"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "from opendxa.common.resource.llm.providers import OpenAIProvider, AnthropicProvider\n\n# Configure LLM resources for planning and reasoning\nplanning_llm = LLMResource(\n    name=\"planning_llm\",\n    provider=OpenAIProvider(\n        model=\"gpt-4\",\n        api_key=\"your-api-key\"  # Replace with your actual API key\n    )\n)\n\nreasoning_llm = LLMResource(\n    name=\"reasoning_llm\",\n    provider=AnthropicProvider(\n        model=\"claude-3-opus\",\n        api_key=\"your-api-key\"  # Replace with your actual API key\n    )\n)\n\n# Configure database resource\ndatabase = DatabaseResource(\n    connection_string=\"postgresql://user:pass@localhost:5432/manufacturing\"\n)\n\n# Configure API resource\napi = APIResource(\n    base_url=\"https://api.example.com\",\n    api_key=\"your-api-key\"  # Replace with your actual API key\n)\n\n# Initialize resources\nawait planning_llm.initialize()\nawait reasoning_llm.initialize()\nawait database.initialize()\nawait api.initialize()\n\nprint(\"Resources initialized:\")\nprint(f\"- Planning LLM: {planning_llm.name}\")\nprint(f\"- Reasoning LLM: {reasoning_llm.name}\")\nprint(f\"- Database: {database.connection_string}\")\nprint(f\"- API: {api.base_url}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. Resource Lifecycle Management\n\nResources need to be properly managed throughout their lifecycle. Let's see how to handle this:"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "from opendxa.execution import ExecutionContext\n\n# Create execution context\ncontext = ExecutionContext()\n\n# Register resources\ncontext.register_resource(planning_llm)\ncontext.register_resource(reasoning_llm)\ncontext.register_resource(database)\ncontext.register_resource(api)\n\n# Use resources in planning\nplanning_result = await context.planning_llm.generate(\n    prompt=\"Create a plan for analyzing manufacturing data\"\n)\nprint(\"Planning Result:\", planning_result)\n\n# Use resources in reasoning\nreasoning_result = await context.reasoning_llm.generate(\n    prompt=\"Analyze this manufacturing data\"\n)\nprint(\"Reasoning Result:\", reasoning_result)\n\n# Use database resource\ndb_result = await database.query(\"SELECT * FROM manufacturing_data\")\nprint(\"Database Result:\", db_result)\n\n# Use API resource\napi_result = await api.make_request(\n    endpoint=\"/manufacturing/analysis\",\n    method=\"POST\",\n    data={\"data\": \"sample_data\"}\n)\nprint(\"API Result:\", api_result)\n\n# Cleanup resources\nawait planning_llm.cleanup()\nawait reasoning_llm.cleanup()\nawait database.cleanup()\nawait api.cleanup()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Resource Pooling and Optimization\n\nResource pooling can help optimize resource usage. Let's see how to implement this:"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "from opendxa.common.resource.pool import ResourcePool\n\n# Create resource pools\nllm_pool = ResourcePool(\n    name=\"llm_pool\",\n    resource_type=LLMResource,\n    max_size=5\n)\n\ndb_pool = ResourcePool(\n    name=\"db_pool\",\n    resource_type=DatabaseResource,\n    max_size=3\n)\n\n# Add resources to pools\nawait llm_pool.add_resource(planning_llm)\nawait llm_pool.add_resource(reasoning_llm)\nawait db_pool.add_resource(database)\n\n# Get resources from pools\nllm = await llm_pool.acquire()\ndb = await db_pool.acquire()\n\n# Use resources\nresult = await llm.generate(prompt=\"Analyze data\")\nprint(\"LLM Result:\", result)\n\n# Release resources back to pools\nawait llm_pool.release(llm)\nawait db_pool.release(db)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. Best Practices\n\nHere are some best practices for working with resources in OpenDXA:\n\n1. **Resource Initialization**:\n   - Initialize resources before use\n   - Handle initialization errors gracefully\n   - Use resource pools for better efficiency\n\n2. **Resource Usage**:\n   - Use appropriate resources for each layer\n   - Implement proper error handling\n   - Monitor resource usage and performance\n\n3. **Resource Cleanup**:\n   - Always clean up resources when done\n   - Handle cleanup errors gracefully\n   - Use context managers when possible\n\n4. **Resource Configuration**:\n   - Use environment variables for sensitive data\n   - Implement proper logging\n   - Use configuration files for complex setups"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Next Steps\n\nIn this tutorial, we've covered:\n\n1. Understanding different types of resources\n2. Configuring and managing resources\n3. Resource lifecycle management\n4. Resource pooling and optimization\n5. Best practices for resource usage\n\nIn the next tutorial, we'll explore tool calling in OpenDXA, which allows agents to interact with external tools and services."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
