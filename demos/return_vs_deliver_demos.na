# Return vs Deliver: Impactful Differences Demo

## Demo 1: Expensive Computation - Lazy vs Eager

### Scenario: ML Model Loading
```dana
# Lazy approach - model only loads when accessed
def load_large_model(model_name: str) -> MLModel:
    print(f"ğŸš€ Starting to load {model_name}...")
    # Simulate expensive model loading
    for i in range(1000000):
        pass  # Expensive computation
    print(f"âœ… {model_name} loaded successfully!")
    return MLModel(model_name)

# Eager approach - model loads immediately
def load_small_model(model_name: str) -> MLModel:
    print(f"ğŸš€ Starting to load {model_name}...")
    # Simulate quick model loading
    for i in range(1000):
        pass  # Quick computation
    print(f"âœ… {model_name} loaded successfully!")
    deliver MLModel(model_name)

# Usage comparison
print("=== LAZY APPROACH ===")
print("Creating model reference (no loading yet)...")
lazy_model = load_large_model("GPT-4")  # Returns immediately with Promise[T]
print("Model reference created, but model not loaded yet!")
print("Now accessing model...")
model_name = lazy_model.name  # NOW the expensive loading happens
print("Model accessed!")

print("\n=== EAGER APPROACH ===")
print("Creating model reference (loading immediately)...")
eager_model = load_small_model("BERT")  # Loads immediately
print("Model reference created and model already loaded!")
model_name = eager_model.name  # Already loaded, instant access
print("Model accessed!")
```

## Demo 2: API Calls - Parallel vs Sequential

### Scenario: Multiple API Calls
```dana
# Lazy API calls - can be parallelized
def fetch_user_data(user_id: str) -> dict:
    print(f"ğŸŒ Fetching user {user_id} from API...")
    # Simulate API call
    for i in range(100000):
        pass
    print(f"âœ… User {user_id} data received!")
    return {"user_id": user_id, "name": f"User{user_id}", "data": "..."}

def fetch_user_posts(user_id: str) -> list:
    print(f"ğŸŒ Fetching posts for user {user_id}...")
    # Simulate API call
    for i in range(80000):
        pass
    print(f"âœ… Posts for user {user_id} received!")
    return [{"post_id": f"p{i}", "content": f"Post {i}"} for i in range(5)]

def fetch_user_friends(user_id: str) -> list:
    print(f"ğŸŒ Fetching friends for user {user_id}...")
    # Simulate API call
    for i in range(60000):
        pass
    print(f"âœ… Friends for user {user_id} received!")
    return [{"friend_id": f"f{i}", "name": f"Friend{i}"} for i in range(3)]

# Eager API call - loads immediately
def fetch_user_profile(user_id: str) -> dict:
    print(f"ğŸŒ Fetching profile for user {user_id}...")
    # Simulate API call
    for i in range(50000):
        pass
    print(f"âœ… Profile for user {user_id} received!")
    deliver {"user_id": user_id, "profile": "Complete profile data"}

# Usage comparison
print("=== LAZY APPROACH (Parallel) ===")
print("Creating API call references...")
user_data = fetch_user_data("123")      # Returns Promise[T] immediately
user_posts = fetch_user_posts("123")    # Returns Promise[T] immediately  
user_friends = fetch_user_friends("123") # Returns Promise[T] immediately
print("All API calls queued but not executed yet!")

print("Now accessing all data (executes in parallel)...")
combined_data = {
    "user": user_data,
    "posts": user_posts, 
    "friends": user_friends
}
print("All data accessed and resolved in parallel!")

print("\n=== EAGER APPROACH (Sequential) ===")
print("Fetching profile immediately...")
profile = fetch_user_profile("456")  # Executes immediately
print("Profile fetched and ready!")
profile_data = profile.profile  # Instant access
print("Profile accessed!")
```

## Demo 3: Database Operations - Conditional Loading

### Scenario: Conditional Database Queries
```dana
# Lazy database query - only executes if needed
def get_user_preferences(user_id: str) -> dict:
    print(f"ğŸ—„ï¸ Querying preferences for user {user_id}...")
    # Simulate database query
    for i in range(50000):
        pass
    print(f"âœ… Preferences for user {user_id} retrieved!")
    return {"theme": "dark", "language": "en", "notifications": True}

def get_user_history(user_id: str) -> list:
    print(f"ğŸ—„ï¸ Querying history for user {user_id}...")
    # Simulate database query
    for i in range(100000):
        pass
    print(f"âœ… History for user {user_id} retrieved!")
    return [{"action": f"action{i}", "timestamp": f"2024-{i}"} for i in range(10)]

# Eager database query - always executes
def get_user_basic_info(user_id: str) -> dict:
    print(f"ğŸ—„ï¸ Querying basic info for user {user_id}...")
    # Simulate database query
    for i in range(20000):
        pass
    print(f"âœ… Basic info for user {user_id} retrieved!")
    deliver {"user_id": user_id, "name": f"User{user_id}", "email": f"user{user_id}@example.com"}

# Usage comparison
print("=== LAZY APPROACH (Conditional) ===")
print("Creating query references...")
preferences = get_user_preferences("789")  # Promise[T] - not executed yet
history = get_user_history("789")          # Promise[T] - not executed yet
print("Queries queued but not executed!")

# Only execute if user wants to see preferences
show_preferences = true
if show_preferences:
    print("User wants preferences, executing query...")
    user_prefs = preferences.theme  # NOW the query executes
    print(f"User theme: {user_prefs}")
else:
    print("User doesn't want preferences, query never executed!")

# Only execute if user wants to see history  
show_history = false
if show_history:
    print("User wants history, executing query...")
    user_hist = history[0]  # This would execute the query
    print(f"First action: {user_hist}")
else:
    print("User doesn't want history, query never executed!")

print("\n=== EAGER APPROACH (Always Executes) ===")
print("Fetching basic info immediately...")
basic_info = get_user_basic_info("789")  # Always executes
print("Basic info fetched!")
user_name = basic_info.name  # Instant access
print(f"User name: {user_name}")
```

## Demo 4: File Operations - Large vs Small Files

### Scenario: File Processing
```dana
# Lazy file processing - only loads if accessed
def load_large_dataset(file_path: str) -> Dataset:
    print(f"ğŸ“ Loading large dataset from {file_path}...")
    # Simulate loading large file
    for i in range(2000000):
        pass
    print(f"âœ… Large dataset loaded from {file_path}!")
    return Dataset(file_path, size="2GB")

def process_small_config(file_path: str) -> Config:
    print(f"ğŸ“ Processing small config from {file_path}...")
    # Simulate processing small file
    for i in range(1000):
        pass
    print(f"âœ… Small config processed from {file_path}!")
    deliver Config(file_path, size="1KB")

# Usage comparison
print("=== LAZY APPROACH (Large Files) ===")
print("Creating dataset reference...")
dataset = load_large_dataset("data/transactions.csv")  # Returns immediately
print("Dataset reference created, file not loaded yet!")

# Only load if analysis is needed
run_analysis = false
if run_analysis:
    print("Analysis needed, loading dataset...")
    data_size = dataset.size  # NOW the large file loads
    print(f"Dataset loaded: {data_size}")
else:
    print("No analysis needed, large file never loaded!")

print("\n=== EAGER APPROACH (Small Files) ===")
print("Processing config immediately...")
config = process_small_config("config/settings.json")  # Processes immediately
print("Config processed!")
config_size = config.size  # Instant access
print(f"Config size: {config_size}")
```

## Demo 5: Real-World Impact - Agent System

### Scenario: Multi-Agent System
```dana
# Lazy agent initialization - only initializes if used
def create_ml_agent(domain: str) -> Agent:
    print(f"ğŸ¤– Initializing ML agent for {domain}...")
    # Simulate expensive agent initialization
    for i in range(1500000):
        pass
    print(f"âœ… ML agent for {domain} initialized!")
    return Agent(domain, capabilities=["prediction", "training"])

def create_simple_agent(domain: str) -> Agent:
    print(f"ğŸ¤– Creating simple agent for {domain}...")
    # Simulate quick agent creation
    for i in range(1000):
        pass
    print(f"âœ… Simple agent for {domain} created!")
    deliver Agent(domain, capabilities=["basic"])

# Usage comparison
print("=== LAZY APPROACH (Multi-Agent) ===")
print("Creating agent references...")
ml_agent = create_ml_agent("semiconductor")  # Promise[T] - not initialized
data_agent = create_ml_agent("data_processing")  # Promise[T] - not initialized
monitoring_agent = create_ml_agent("monitoring")  # Promise[T] - not initialized
print("All agent references created, none initialized yet!")

# Only initialize agents that are actually needed
use_ml = true
use_data = false
use_monitoring = true

if use_ml:
    print("ML agent needed, initializing...")
    ml_capabilities = ml_agent.capabilities  # NOW initializes
    print(f"ML agent ready: {ml_capabilities}")

if use_data:
    print("Data agent needed, initializing...")
    data_capabilities = data_agent.capabilities  # Would initialize
    print(f"Data agent ready: {data_capabilities}")

if use_monitoring:
    print("Monitoring agent needed, initializing...")
    monitoring_capabilities = monitoring_agent.capabilities  # NOW initializes
    print(f"Monitoring agent ready: {monitoring_capabilities}")

print("\n=== EAGER APPROACH (Simple Agent) ===")
print("Creating simple agent immediately...")
simple_agent = create_simple_agent("basic")  # Creates immediately
print("Simple agent created!")
simple_capabilities = simple_agent.capabilities  # Instant access
print(f"Simple agent ready: {simple_capabilities}")
```

## Demo 6: Performance Comparison

### Scenario: Benchmarking Return vs Deliver
```dana
# Performance test functions
def expensive_operation_lazy() -> str:
    print("ğŸ”„ Starting expensive lazy operation...")
    for i in range(1000000):
        pass
    print("âœ… Expensive lazy operation completed!")
    return "lazy_result"

def expensive_operation_eager() -> str:
    print("ğŸ”„ Starting expensive eager operation...")
    for i in range(1000000):
        pass
    print("âœ… Expensive eager operation completed!")
    deliver "eager_result"

def quick_operation_eager() -> str:
    print("âš¡ Starting quick eager operation...")
    for i in range(1000):
        pass
    print("âœ… Quick eager operation completed!")
    deliver "quick_result"

# Performance comparison
print("=== PERFORMANCE COMPARISON ===")

print("\n1. Lazy Operation (Return)")
print("Creating reference...")
lazy_result = expensive_operation_lazy()  # Returns immediately
print("Reference created in ~0ms")
print("Accessing result...")
result = lazy_result  # NOW executes expensive operation
print("Result accessed!")

print("\n2. Eager Operation (Deliver)")
print("Creating and executing...")
eager_result = expensive_operation_eager()  # Executes immediately
print("Result created and ready!")
result = eager_result  # Instant access
print("Result accessed!")

print("\n3. Quick Eager Operation (Deliver)")
print("Creating and executing...")
quick_result = quick_operation_eager()  # Executes immediately
print("Result created and ready!")
result = quick_result  # Instant access
print("Result accessed!")

print("\n=== KEY INSIGHTS ===")
print("â€¢ Lazy (return): Fast creation, deferred execution")
print("â€¢ Eager (deliver): Immediate execution, instant access")
print("â€¢ Use lazy for expensive operations that might not be needed")
print("â€¢ Use eager for quick operations that are always needed")
print("â€¢ Lazy enables parallel execution when multiple operations are accessed together")
```

## Demo 7: Error Handling Differences

### Scenario: Error Propagation
```dana
# Lazy operation that might fail
def risky_operation_lazy() -> str:
    print("ğŸ² Starting risky lazy operation...")
    # Simulate operation that might fail
    import random
    if random.random() < 0.5:
        raise Exception("Lazy operation failed!")
    print("âœ… Risky lazy operation succeeded!")
    return "lazy_success"

# Eager operation that might fail
def risky_operation_eager() -> str:
    print("ğŸ² Starting risky eager operation...")
    # Simulate operation that might fail
    import random
    if random.random() < 0.5:
        raise Exception("Eager operation failed!")
    print("âœ… Risky eager operation succeeded!")
    deliver "eager_success"

# Error handling comparison
print("=== ERROR HANDLING COMPARISON ===")

print("\n1. Lazy Error Handling")
try:
    print("Creating lazy reference...")
    lazy_result = risky_operation_lazy()  # No error yet
    print("Reference created successfully!")
    
    print("Accessing result...")
    result = lazy_result  # Error happens here
    print("Result accessed successfully!")
except Exception as e:
    print(f"âŒ Error caught: {e}")

print("\n2. Eager Error Handling")
try:
    print("Creating and executing eager operation...")
    eager_result = risky_operation_eager()  # Error happens here
    print("Operation completed successfully!")
    
    print("Accessing result...")
    result = eager_result  # No error here
    print("Result accessed successfully!")
except Exception as e:
    print(f"âŒ Error caught: {e}")

print("\n=== KEY DIFFERENCES ===")
print("â€¢ Lazy: Errors occur when accessing the result")
print("â€¢ Eager: Errors occur when creating the result")
print("â€¢ Lazy: Can create multiple references before any errors")
print("â€¢ Eager: Errors prevent result creation entirely")
```

## Summary: When to Use Each

### Use `return` (Lazy) When:
- **Expensive operations** that might not be needed
- **Multiple operations** that can be parallelized
- **Conditional execution** based on runtime decisions
- **Large resource loading** (files, models, databases)
- **API calls** that might not be accessed

### Use `deliver` (Eager) When:
- **Quick operations** that are always needed
- **Immediate validation** is required
- **Error handling** should happen early
- **Small resources** that load quickly
- **Always-accessed data** (configuration, basic info)

### Performance Impact:
- **Lazy**: Fast creation, deferred execution, potential parallelization
- **Eager**: Immediate execution, instant access, predictable timing

This dual delivery system gives developers fine-grained control over execution timing while maintaining transparent typing and automatic parallelization! 