# Objective-Driven State Machine Agent
# Implements a 6-phase execution cycle for semiconductor process control

import log
import time
import uuid
import statistics
from enhanced_poet import objective_poet
from data_structures import *

# Define the Objective-Driven Agent
struct ObjectiveDrivenAgent:
    name: str
    description: str
    current_state: ProcessState
    current_objective: str
    objective_status: str  # "pending", "in_progress", "completed", "failed"
    learning_enabled: bool
    metrics: list[dict]
    context: StateMachineContext
    process_specs: dict  # Parameter specifications
    
    def __init__(self, name: str, description: str = ""):
        self.name = name
        self.description = description
        self.current_state = ProcessState.IDLE
        self.current_objective = "idle"
        self.objective_status = "pending"
        self.learning_enabled = True
        self.metrics = []
        self.context = StateMachineContext(
            current_state=ProcessState.IDLE,
            previous_state=ProcessState.IDLE,
            state_history=[],
            active_objective="initialize",
            optimization_target="reliability",
            execution_id=str(uuid.uuid4()),
            start_time=time.now()
        )
        self.process_specs = {}
    
    def collect_metrics(self, metric: dict):
        """Collect metrics for learning and optimization"""
        self.metrics.append(metric)
        if len(self.metrics) > 1000:  # Keep last 1000 metrics
            self.metrics = self.metrics[-1000:]
    
    def set_process_specs(self, specs: dict):
        """Set process parameter specifications"""
        self.process_specs = specs

# State Machine Functions with Objectives

@objective_poet(
    domain="semiconductor",
    objective="analyze process parameters for anomalies",
    optimize_for="accuracy"
)
def analyze_process_data(agent: ObjectiveDrivenAgent, data: ProcessDataBatch) -> dict:
    """Analyze process data to identify patterns and anomalies"""
    agent.current_state = ProcessState.ANALYZING
    agent.context.add_state_transition(ProcessState.ANALYZING)
    
    log(f"📊 Analyzing batch {data.batch_id} with {len(data.parameters)} parameters", "info")
    
    # Group parameters by name
    param_groups = {}
    for param in data.parameters:
        if param.name not in param_groups:
            param_groups[param.name] = []
        param_groups[param.name].append(param)
    
    # Calculate statistics for each parameter
    statistics_results = []
    for param_name, values in param_groups.items():
        if len(values) < 2:
            continue
            
        vals = [p.value for p in values]
        stats = ParameterStats(
            parameter_name=param_name,
            mean=statistics.mean(vals),
            std_dev=statistics.stdev(vals) if len(vals) > 1 else 0.0,
            min_value=min(vals),
            max_value=max(vals),
            sample_count=len(vals),
            trend=detect_trend(vals)
        )
        statistics_results.append(stats)
    
    # Detect anomalies
    anomalies = []
    for param_name, values in param_groups.items():
        if param_name in agent.process_specs:
            spec = agent.process_specs[param_name]
            for param in values:
                if not param.is_within_limits(spec["min"], spec["max"]):
                    anomaly = ProcessAnomaly(
                        parameter_name=param_name,
                        detected_at=param.timestamp,
                        severity=determine_severity(param.value, spec),
                        description=f"{param_name} out of range: {param.value} {param.unit}",
                        confidence=0.95,
                        suggested_action=f"Adjust {param_name} to target range [{spec['min']}, {spec['max']}]"
                    )
                    anomalies.append(anomaly)
    
    return {
        "batch_id": data.batch_id,
        "statistics": statistics_results,
        "anomalies": anomalies,
        "parameter_count": len(data.parameters),
        "anomaly_count": len(anomalies)
    }

@objective_poet(
    domain="semiconductor",
    objective="diagnose root causes of process anomalies",
    optimize_for="reliability"
)
def diagnose_anomalies(agent: ObjectiveDrivenAgent, analysis_result: dict) -> dict:
    """Diagnose root causes of detected anomalies"""
    agent.current_state = ProcessState.DIAGNOSING
    agent.context.add_state_transition(ProcessState.DIAGNOSING)
    
    anomalies = analysis_result["anomalies"]
    statistics = analysis_result["statistics"]
    
    log(f"🔍 Diagnosing {len(anomalies)} anomalies", "info")
    
    # Group anomalies by parameter
    anomaly_groups = {}
    for anomaly in anomalies:
        if anomaly.parameter_name not in anomaly_groups:
            anomaly_groups[anomaly.parameter_name] = []
        anomaly_groups[anomaly.parameter_name].append(anomaly)
    
    # Perform root cause analysis
    diagnoses = []
    for param_name, param_anomalies in anomaly_groups.items():
        # Find corresponding statistics
        param_stats = None
        for stats in statistics:
            if stats.parameter_name == param_name:
                param_stats = stats
                break
        
        if param_stats:
            # Analyze patterns
            if param_stats.coefficient_of_variation() > 0.15:
                diagnoses.append({
                    "parameter": param_name,
                    "issue": "high_variability",
                    "severity": "warning",
                    "root_cause": f"Process instability - CV={param_stats.coefficient_of_variation():.2f}",
                    "recommendation": "Investigate equipment calibration and environmental factors"
                })
            
            if param_stats.trend == "increasing" and len(param_anomalies) > 2:
                diagnoses.append({
                    "parameter": param_name,
                    "issue": "drift",
                    "severity": "error",
                    "root_cause": "Systematic drift detected in parameter values",
                    "recommendation": "Perform equipment maintenance and recalibration"
                })
    
    # Check for correlated anomalies
    if len(anomaly_groups) > 1:
        param_names = list(anomaly_groups.keys())
        correlations = check_parameter_correlations(param_names, statistics)
        for correlation in correlations:
            diagnoses.append({
                "parameter": f"{correlation['param1']},{correlation['param2']}",
                "issue": "correlation",
                "severity": "info",
                "root_cause": f"Parameters show {correlation['strength']} correlation",
                "recommendation": "Consider coupled control strategy"
            })
    
    return {
        "diagnoses": diagnoses,
        "total_issues": len(diagnoses),
        "critical_issues": len([d for d in diagnoses if d["severity"] == "error"]),
        "recommendations": [d["recommendation"] for d in diagnoses]
    }

@objective_poet(
    domain="semiconductor",
    objective="optimize process parameters for yield improvement",
    optimize_for="efficiency"
)
def optimize_parameters(agent: ObjectiveDrivenAgent, diagnosis_result: dict) -> dict:
    """Generate optimization recommendations based on diagnosis"""
    agent.current_state = ProcessState.OPTIMIZING
    agent.context.add_state_transition(ProcessState.OPTIMIZING)
    
    diagnoses = diagnosis_result["diagnoses"]
    
    log(f"⚡ Generating optimizations for {len(diagnoses)} diagnosed issues", "info")
    
    optimizations = []
    for diagnosis in diagnoses:
        if diagnosis["issue"] == "high_variability":
            # Recommend tighter control limits
            param_name = diagnosis["parameter"]
            if param_name in agent.process_specs:
                spec = agent.process_specs[param_name]
                target = (spec["min"] + spec["max"]) / 2
                
                optimization = OptimizationRecommendation(
                    parameter_name=param_name,
                    current_value=target,  # Using target as reference
                    recommended_value=target,
                    expected_improvement=15.0,  # 15% yield improvement
                    confidence=0.8,
                    rationale="Reduce variability by tightening control around target value"
                )
                optimizations.append(optimization)
        
        elif diagnosis["issue"] == "drift":
            # Recommend corrective action
            param_name = diagnosis["parameter"]
            if param_name in agent.process_specs:
                spec = agent.process_specs[param_name]
                target = (spec["min"] + spec["max"]) / 2
                
                optimization = OptimizationRecommendation(
                    parameter_name=param_name,
                    current_value=spec["max"],  # Assuming drift to upper limit
                    recommended_value=target,
                    expected_improvement=20.0,  # 20% yield improvement
                    confidence=0.9,
                    rationale="Correct systematic drift by returning to target value"
                )
                optimizations.append(optimization)
    
    # Calculate overall optimization potential
    total_improvement = sum(opt.expected_improvement for opt in optimizations) / len(optimizations) if optimizations else 0
    
    return {
        "optimizations": optimizations,
        "total_recommendations": len(optimizations),
        "expected_yield_improvement": total_improvement,
        "implementation_priority": rank_optimizations(optimizations)
    }

@objective_poet(
    domain="semiconductor",
    objective="validate optimization recommendations",
    optimize_for="reliability"
)
def validate_optimizations(agent: ObjectiveDrivenAgent, optimization_result: dict) -> dict:
    """Validate optimization recommendations for safety and feasibility"""
    agent.current_state = ProcessState.VALIDATING
    agent.context.add_state_transition(ProcessState.VALIDATING)
    
    optimizations = optimization_result["optimizations"]
    
    log(f"✅ Validating {len(optimizations)} optimization recommendations", "info")
    
    validated_optimizations = []
    validation_issues = []
    
    for opt in optimizations:
        # Check if recommendation is within safe operating limits
        if opt.parameter_name in agent.process_specs:
            spec = agent.process_specs[opt.parameter_name]
            safe_min = spec["min"] * 0.95  # 5% safety margin
            safe_max = spec["max"] * 1.05
            
            if safe_min <= opt.recommended_value <= safe_max:
                # Apply safety factor
                safe_value = opt.apply_factor(0.7)  # 70% of recommended change
                opt.recommended_value = safe_value
                opt.confidence *= 0.9  # Reduce confidence after safety factor
                validated_optimizations.append(opt)
            else:
                validation_issues.append({
                    "parameter": opt.parameter_name,
                    "issue": "out_of_safe_range",
                    "recommended": opt.recommended_value,
                    "safe_range": [safe_min, safe_max]
                })
    
    # Check for conflicting optimizations
    conflicts = check_optimization_conflicts(validated_optimizations)
    for conflict in conflicts:
        validation_issues.append({
            "parameter": f"{conflict['param1']},{conflict['param2']}",
            "issue": "conflicting_optimizations",
            "description": conflict['description']
        })
    
    return {
        "validated_optimizations": validated_optimizations,
        "validation_issues": validation_issues,
        "approval_rate": len(validated_optimizations) / len(optimizations) if optimizations else 0,
        "ready_for_implementation": len(validation_issues) == 0
    }

@objective_poet(
    domain="semiconductor",
    objective="generate comprehensive process health report",
    optimize_for="completeness"
)
def generate_report(agent: ObjectiveDrivenAgent, validation_result: dict, 
                   analysis_result: dict, diagnosis_result: dict) -> ProcessHealthReport:
    """Generate comprehensive process health report"""
    agent.current_state = ProcessState.REPORTING
    agent.context.add_state_transition(ProcessState.REPORTING)
    
    log(f"📝 Generating comprehensive process health report", "info")
    
    # Compile all anomalies
    all_anomalies = analysis_result.get("anomalies", [])
    
    # Compile all optimizations
    all_optimizations = validation_result.get("validated_optimizations", [])
    
    # Compile all statistics
    all_statistics = analysis_result.get("statistics", [])
    
    # Calculate overall health score
    total_params = analysis_result.get("parameter_count", 0)
    anomaly_count = len(all_anomalies)
    health_score = 1.0 - (anomaly_count / total_params) if total_params > 0 else 1.0
    
    # Adjust health score based on severity
    critical_issues = [a for a in all_anomalies if a.severity == AlertSeverity.CRITICAL]
    if critical_issues:
        health_score *= 0.5  # Reduce by 50% if critical issues exist
    
    # Create report
    report = ProcessHealthReport(
        timestamp=time.now(),
        overall_health=health_score,
        parameters_analyzed=total_params,
        anomalies_detected=all_anomalies,
        optimizations=all_optimizations,
        statistics=all_statistics
    )
    
    # Log summary
    log(f"📊 Report Summary:", "info")
    log(f"  - Overall Health: {health_score:.1%}", "info")
    log(f"  - Parameters Analyzed: {total_params}", "info")
    log(f"  - Anomalies Detected: {anomaly_count}", "info")
    log(f"  - Optimizations Recommended: {len(all_optimizations)}", "info")
    
    # Transition back to idle
    agent.current_state = ProcessState.IDLE
    agent.context.add_state_transition(ProcessState.IDLE)
    
    return report

# State Machine Orchestrator
@objective_poet(
    domain="semiconductor",
    objective="orchestrate complete analysis cycle",
    optimize_for="completeness"
)
def execute_state_machine(agent: ObjectiveDrivenAgent, process_data: ProcessDataBatch) -> ProcessHealthReport:
    """Execute the complete state machine cycle"""
    log(f"🚀 Starting state machine execution for batch {process_data.batch_id}", "info")
    
    try:
        # Phase 1: Analyze
        analysis_result = analyze_process_data(agent, process_data)
        
        # Phase 2: Diagnose
        diagnosis_result = diagnose_anomalies(agent, analysis_result)
        
        # Phase 3: Optimize
        optimization_result = optimize_parameters(agent, diagnosis_result)
        
        # Phase 4: Validate
        validation_result = validate_optimizations(agent, optimization_result)
        
        # Phase 5: Report
        report = generate_report(agent, validation_result, analysis_result, diagnosis_result)
        
        log(f"✅ State machine execution completed successfully", "info")
        log(f"⏱️ Total execution time: {agent.context.get_execution_duration():.2f}s", "debug")
        
        return report
        
    except Exception as e:
        agent.current_state = ProcessState.ERROR
        agent.context.add_state_transition(ProcessState.ERROR)
        log(f"❌ State machine execution failed: {e}", "error")
        raise e

# Helper Functions

def detect_trend(values: list[float]) -> str:
    """Detect trend in time series values"""
    if len(values) < 3:
        return "stable"
    
    # Simple linear trend detection
    n = len(values)
    x_sum = sum(range(n))
    y_sum = sum(values)
    xy_sum = sum(i * v for i, v in enumerate(values))
    x2_sum = sum(i * i for i in range(n))
    
    # Calculate slope
    denominator = n * x2_sum - x_sum * x_sum
    if denominator == 0:
        return "stable"
    
    slope = (n * xy_sum - x_sum * y_sum) / denominator
    
    # Determine trend based on slope
    if slope > 0.01:
        return "increasing"
    elif slope < -0.01:
        return "decreasing"
    else:
        return "stable"

def determine_severity(value: float, spec: dict) -> AlertSeverity:
    """Determine severity based on how far value is from spec limits"""
    min_val = spec["min"]
    max_val = spec["max"]
    range_size = max_val - min_val
    
    if min_val <= value <= max_val:
        return AlertSeverity.INFO
    
    # Calculate deviation percentage
    if value < min_val:
        deviation = (min_val - value) / range_size
    else:
        deviation = (value - max_val) / range_size
    
    if deviation < 0.1:
        return AlertSeverity.WARNING
    elif deviation < 0.2:
        return AlertSeverity.ERROR
    else:
        return AlertSeverity.CRITICAL

def check_parameter_correlations(param_names: list[str], statistics: list[ParameterStats]) -> list[dict]:
    """Check for correlations between parameters"""
    correlations = []
    
    # Simple correlation check based on trends
    for i in range(len(param_names)):
        for j in range(i + 1, len(param_names)):
            stats1 = next((s for s in statistics if s.parameter_name == param_names[i]), None)
            stats2 = next((s for s in statistics if s.parameter_name == param_names[j]), None)
            
            if stats1 and stats2 and stats1.trend == stats2.trend and stats1.trend != "stable":
                correlations.append({
                    "param1": param_names[i],
                    "param2": param_names[j],
                    "strength": "positive" if stats1.trend == stats2.trend else "negative"
                })
    
    return correlations

def rank_optimizations(optimizations: list[OptimizationRecommendation]) -> list[str]:
    """Rank optimizations by priority"""
    # Sort by expected improvement and confidence
    sorted_opts = sorted(
        optimizations,
        key=lambda x: x.expected_improvement * x.confidence,
        reverse=True
    )
    
    return [opt.parameter_name for opt in sorted_opts]

def check_optimization_conflicts(optimizations: list[OptimizationRecommendation]) -> list[dict]:
    """Check for conflicting optimization recommendations"""
    conflicts = []
    
    # Simple conflict detection - parameters that interact
    interaction_pairs = [
        ("temperature", "pressure"),
        ("flow_rate", "residence_time"),
        ("power", "temperature")
    ]
    
    for pair in interaction_pairs:
        opt1 = next((o for o in optimizations if o.parameter_name == pair[0]), None)
        opt2 = next((o for o in optimizations if o.parameter_name == pair[1]), None)
        
        if opt1 and opt2:
            # Check if optimizations move in opposite directions
            if (opt1.recommended_value > opt1.current_value and 
                opt2.recommended_value < opt2.current_value):
                conflicts.append({
                    "param1": pair[0],
                    "param2": pair[1],
                    "description": "Optimizations may have opposing effects"
                })
    
    return conflicts

# Export main components
export ObjectiveDrivenAgent, execute_state_machine
export analyze_process_data, diagnose_anomalies, optimize_parameters
export validate_optimizations, generate_report